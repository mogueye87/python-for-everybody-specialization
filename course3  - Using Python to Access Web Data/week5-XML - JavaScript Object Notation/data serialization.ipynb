{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using python to access web data\n",
    "\n",
    "- Serialization \n",
    "- XML data format \n",
    "- XML parsing with ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "data = '''\n",
    "<person>\n",
    "  <name>Chuck</name>\n",
    "  <phone type=\"intl\">\n",
    "    +1 734 303 4456\n",
    "  </phone>\n",
    "  <email hide=\"yes\" />\n",
    "</person>'''\n",
    "\n",
    "# call of the method fromstring to parse the xml data to an object\n",
    "tree = ET.fromstring(data)\n",
    "# extract the name from the xml element\n",
    "name = tree.find('name').text\n",
    "email = tree.find('email').get('hide')\n",
    "print('Name:', name)\n",
    "print('Attr:', email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked example: Xml \n",
    "## Example 2: cas d'un fichier XML, findall method of ElemeentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "input = '''\n",
    "<stuff>\n",
    "  <users>\n",
    "    <user x=\"2\">\n",
    "      <id>001</id>\n",
    "      <name>Chuck</name>\n",
    "    </user>\n",
    "    <user x=\"7\">\n",
    "      <id>009</id>\n",
    "      <name>Brent</name>\n",
    "    </user>\n",
    "  </users>\n",
    "</stuff>'''\n",
    "\n",
    "stuff = ET.fromstring(input)\n",
    "lst = stuff.findall('users/user')\n",
    "print('User count:', len(lst))\n",
    "\n",
    "for item in lst:\n",
    "    print('Name', item.find('name').text)\n",
    "    print('Id', item.find('id').text)\n",
    "    print('Attribute', item.get('x'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping \n",
    "- utiliser urllib pour extraire des données sur le web\n",
    "- BeautifulSoup pour parser du html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2311"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request, urllib.error, urllib.response\n",
    "import xml.etree.ElementTree as ET\n",
    "import ssl\n",
    "\n",
    "# creation d'une chaine de caractère \n",
    "def convertXMLToString(fhand):\n",
    "    message = \"\"\n",
    "    for line in fhand:\n",
    "        word = line.decode() \n",
    "        message += word\n",
    "    return message\n",
    "\n",
    "dataString = convertXMLToString(fhand)\n",
    "print(dataString)\n",
    "\n",
    "fhand = urllib.request.urlopen(\"http://py4e-data.dr-chuck.net/comments_193217.xml\")\n",
    "dataString = convertXMLToString(fhand)\n",
    "data = ET.fromstring(dataString)\n",
    "comments = data.findall('comments/comment')\n",
    "comment_dict = {}\n",
    "for comment in comments:\n",
    "    name = comment.find('name').text\n",
    "    count = comment.find('count').text\n",
    "    comment_dict[name] = comment_dict.get(name, 0) + int(count)\n",
    "comment_dict\n",
    "sum(comment_dict.values())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
